{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:02:33.329550Z",
     "iopub.status.busy": "2025-12-03T14:02:33.328814Z",
     "iopub.status.idle": "2025-12-03T14:02:38.444670Z",
     "shell.execute_reply": "2025-12-03T14:02:38.443586Z",
     "shell.execute_reply.started": "2025-12-03T14:02:33.329522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "!pip install protobuf==3.20.3\n",
    "# for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:02:38.446753Z",
     "iopub.status.busy": "2025-12-03T14:02:38.446186Z",
     "iopub.status.idle": "2025-12-03T14:02:42.119728Z",
     "shell.execute_reply": "2025-12-03T14:02:42.118795Z",
     "shell.execute_reply.started": "2025-12-03T14:02:38.446724Z"
    },
    "papermill": {
     "duration": 0.01316,
     "end_time": "2025-11-19T14:54:18.792965",
     "exception": false,
     "start_time": "2025-11-19T14:54:18.779805",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "path = \"/kaggle/input/code-review-model-train-test-val-jsnol-files/train_data.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ex = json.loads(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:02:42.121101Z",
     "iopub.status.busy": "2025-12-03T14:02:42.120699Z",
     "iopub.status.idle": "2025-12-03T14:03:34.134730Z",
     "shell.execute_reply": "2025-12-03T14:03:34.134027Z",
     "shell.execute_reply.started": "2025-12-03T14:02:42.121080Z"
    },
    "papermill": {
     "duration": 13.709932,
     "end_time": "2025-11-19T14:54:32.505469",
     "exception": false,
     "start_time": "2025-11-19T14:54:18.795537",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
    "model_name = 't5-small'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:03:34.136820Z",
     "iopub.status.busy": "2025-12-03T14:03:34.136279Z",
     "iopub.status.idle": "2025-12-03T14:03:34.140632Z",
     "shell.execute_reply": "2025-12-03T14:03:34.139910Z",
     "shell.execute_reply.started": "2025-12-03T14:03:34.136796Z"
    },
    "papermill": {
     "duration": 0.008183,
     "end_time": "2025-11-19T14:54:32.516917",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.508734",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_input_tok = 256\n",
    "max_target_tok = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:03:34.141802Z",
     "iopub.status.busy": "2025-12-03T14:03:34.141374Z",
     "iopub.status.idle": "2025-12-03T14:03:34.162685Z",
     "shell.execute_reply": "2025-12-03T14:03:34.161881Z",
     "shell.execute_reply.started": "2025-12-03T14:03:34.141782Z"
    },
    "papermill": {
     "duration": 0.016069,
     "end_time": "2025-11-19T14:54:32.535872",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.519803",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "enc_inputs = tokenizer(ex['prompt'], truncation = True, max_length = max_input_tok)\n",
    "enc_target = tokenizer(ex['completion'], truncation = True, max_length = max_target_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:03:34.163856Z",
     "iopub.status.busy": "2025-12-03T14:03:34.163568Z",
     "iopub.status.idle": "2025-12-03T14:03:34.176518Z",
     "shell.execute_reply": "2025-12-03T14:03:34.175806Z",
     "shell.execute_reply.started": "2025-12-03T14:03:34.163836Z"
    },
    "papermill": {
     "duration": 0.009398,
     "end_time": "2025-11-19T14:54:32.548298",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.538900",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(enc_inputs['input_ids'])\n",
    "attention_mask = torch.tensor(enc_inputs['attention_mask'])\n",
    "labels = torch.tensor(enc_target['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:03:34.177753Z",
     "iopub.status.busy": "2025-12-03T14:03:34.177434Z",
     "iopub.status.idle": "2025-12-03T14:03:34.192309Z",
     "shell.execute_reply": "2025-12-03T14:03:34.191318Z",
     "shell.execute_reply.started": "2025-12-03T14:03:34.177724Z"
    },
    "papermill": {
     "duration": 0.008541,
     "end_time": "2025-11-19T14:54:32.574367",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.565826",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"input_ids\" : input_ids.unsqueeze(0),\n",
    "    \"attention_mask\" : attention_mask.unsqueeze(0),\n",
    "    \"labels\" : labels.unsqueeze(0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:03:34.193489Z",
     "iopub.status.busy": "2025-12-03T14:03:34.193201Z",
     "iopub.status.idle": "2025-12-03T14:03:34.208149Z",
     "shell.execute_reply": "2025-12-03T14:03:34.207279Z",
     "shell.execute_reply.started": "2025-12-03T14:03:34.193462Z"
    },
    "papermill": {
     "duration": 0.011683,
     "end_time": "2025-11-19T14:56:25.425974",
     "exception": false,
     "start_time": "2025-11-19T14:56:25.414291",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = [{\"input_ids\": b[\"input_ids\"], \"attention_mask\": b.get(\"attention_mask\", None)} for b in batch]\n",
    "    padded = tokenizer.pad(inputs, return_tensors=\"pt\")\n",
    "\n",
    "    labels = [b[\"labels\"] for b in batch]\n",
    "    padded_labels = tokenizer.pad({\"input_ids\": labels}, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    padded_labels[padded_labels == pad_id] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": padded[\"input_ids\"],\n",
    "        \"attention_mask\": padded[\"attention_mask\"],\n",
    "        \"labels\": padded_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:03:34.209493Z",
     "iopub.status.busy": "2025-12-03T14:03:34.209105Z",
     "iopub.status.idle": "2025-12-03T14:04:35.203110Z",
     "shell.execute_reply": "2025-12-03T14:04:35.202401Z",
     "shell.execute_reply.started": "2025-12-03T14:03:34.209472Z"
    },
    "papermill": {
     "duration": 43.287067,
     "end_time": "2025-11-19T14:57:08.716479",
     "exception": false,
     "start_time": "2025-11-19T14:56:25.429412",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer,\n",
    "                 max_input_len=256, max_target_len=128):\n",
    "\n",
    "        self.path = path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "\n",
    "        self._offsets = []\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            offset = f.tell()\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                self._offsets.append(offset)\n",
    "                offset = f.tell()\n",
    "                line = f.readline()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._offsets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.seek(self._offsets[idx])\n",
    "            rec = json.loads(f.readline())\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            rec[\"prompt\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_input_len,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        tgt = self.tokenizer(\n",
    "            rec[\"completion\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_target_len\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"labels\": tgt[\"input_ids\"]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "path = \"/kaggle/input/code-review-model-train-test-val-jsnol-files/train_data.jsonl\"\n",
    "\n",
    "train_dataset = PRDataset(\n",
    "    path,\n",
    "    tokenizer,\n",
    "    max_input_len=256,\n",
    "    max_target_len=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T14:04:35.205239Z",
     "iopub.status.busy": "2025-12-03T14:04:35.204935Z",
     "iopub.status.idle": "2025-12-03T14:04:35.218487Z",
     "shell.execute_reply": "2025-12-03T14:04:35.217780Z",
     "shell.execute_reply.started": "2025-12-03T14:04:35.205221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n = len(train_dataset)               # <-- use your actual dataset\n",
    "k = min(3, n)\n",
    "\n",
    "for i in random.sample(range(n), k):\n",
    "    lbl = tokenizer.decode(train_dataset[i]['labels'], skip_special_tokens=True)\n",
    "    print(\"LABEL:\", repr(lbl))\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T10:48:54.399713Z",
     "iopub.status.busy": "2025-12-02T10:48:54.399197Z",
     "iopub.status.idle": "2025-12-02T10:48:55.608165Z",
     "shell.execute_reply": "2025-12-02T10:48:55.607607Z",
     "shell.execute_reply.started": "2025-12-02T10:48:54.399684Z"
    },
    "papermill": {
     "duration": 2.857014,
     "end_time": "2025-11-19T14:57:11.577036",
     "exception": false,
     "start_time": "2025-11-19T14:57:08.720022",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_dataset = PRDataset(\n",
    "    \"/kaggle/input/code-review-model-train-test-val-jsnol-files/val_data.jsonl\",\n",
    "    tokenizer,\n",
    "    max_input_len=256,\n",
    "    max_target_len=128\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T10:48:55.609117Z",
     "iopub.status.busy": "2025-12-02T10:48:55.608872Z",
     "iopub.status.idle": "2025-12-02T10:48:55.963262Z",
     "shell.execute_reply": "2025-12-02T10:48:55.961840Z",
     "shell.execute_reply.started": "2025-12-02T10:48:55.609093Z"
    },
    "papermill": {
     "duration": 0.145573,
     "end_time": "2025-11-19T14:57:11.726594",
     "exception": false,
     "start_time": "2025-11-19T14:57:11.581021",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "assert batch['input_ids'].ndim == 2\n",
    "print(batch['input_ids'].shape, batch['attention_mask'].shape, batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T10:50:23.342712Z",
     "iopub.status.busy": "2025-12-02T10:50:23.342128Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-11-19T14:57:11.730438",
     "status": "running"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import amp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils as nn_utils\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.to(device)\n",
    "\n",
    "ACCUM_STEPS = 8\n",
    "LR = 5e-5                     \n",
    "use_amp = True\n",
    "scaler = amp.GradScaler() if use_amp else None\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "opt_step_count = 0\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    step_count = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        labels = batch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "        if use_amp:\n",
    "            with amp.autocast(device_type=\"cuda\"):\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                    use_cache=False\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "        else:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "                use_cache=False\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        step_count += 1\n",
    "\n",
    "        # gradient accumulation\n",
    "        loss = loss / ACCUM_STEPS\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        # optimizer step\n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            if use_amp:\n",
    "                scaler.unscale_(optimizer)\n",
    "            nn_utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.step(optimizer); scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            opt_step_count += 1\n",
    "\n",
    "    avg_train_loss = total_loss / max(1, step_count)\n",
    "    print(f\"Epoch {epoch} train avg loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for vbatch in val_loader:\n",
    "            v_input_ids = vbatch['input_ids'].to(device, non_blocking=True)\n",
    "            v_attention_mask = vbatch['attention_mask'].to(device, non_blocking=True)\n",
    "            v_labels = vbatch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "            if use_amp:\n",
    "                with amp.autocast(device_type=\"cuda\"):\n",
    "                    vout = model(\n",
    "                        input_ids=v_input_ids,\n",
    "                        attention_mask=v_attention_mask,\n",
    "                        labels=v_labels,\n",
    "                        use_cache=False\n",
    "                    )\n",
    "            else:\n",
    "                vout = model(\n",
    "                    input_ids=v_input_ids,\n",
    "                    attention_mask=v_attention_mask,\n",
    "                    labels=v_labels,\n",
    "                    use_cache=False\n",
    "                )\n",
    "\n",
    "            val_loss += vout.loss.item()\n",
    "            val_steps += 1\n",
    "\n",
    "    print(f\"Epoch {epoch} val avg loss: {val_loss / max(1, val_steps):.4f}\")\n",
    "\n",
    "model.save_pretrained(\"/kaggle/working/\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-02T10:48:56.354802Z",
     "iopub.status.idle": "2025-12-02T10:48:56.355036Z",
     "shell.execute_reply": "2025-12-02T10:48:56.354928Z",
     "shell.execute_reply.started": "2025-12-02T10:48:56.354918Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working/\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8779781,
     "sourceId": 13791082,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-19T14:54:15.193838",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
