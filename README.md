AI Code Review Agent

A transformer-based system that automatically generates high-quality code review comments from GitHub pull request diffs.
The project builds a clean training dataset from PR comments, formats them into a structured review prompt, and fine-tunes a FLAN-T5 model on GPU using a 300k-example subset for memory efficiency.

ğŸš€ Project Overview

This project focuses on generating automated, human-like code review comments.
Due to memory constraints, the full dataset was downsampled to 300k curated examples for training.

Key Goals

Extract structured training pairs from GitHub PR diffs.

Fine-tune FLAN-T5-Small on GPU.

Generate structured review comments with reasoning + minimal patch fixes.

Maintain an efficient data pipeline suitable for consumer GPUs.

ğŸ“¦ Features Implemented
âœ… Diff Parsing & Extraction

A custom streaming diff-parser that performs:

Changed-line detection

Adaptive grouping (3â€“7 lines)

1-line context before & after each changed block

Scoped extraction stopping at next @@ or limit

Indentation normalization only when irregular

Skipping large diff hunks for speed

âœ… Final Prompt Format

Each training sample follows:

Suggested Review:
<rewritten PR comment>

Reasoning:
<brief explanation>

Fix:
Replace these lines:
<old>

With this:
<new>


Formatting adapts:

Single-line fixes â†’ plain text

Multi-line fixes â†’ code blocks

âœ… Dataset Pipeline

Consists of several notebook stages:

Raw â†’ cleaned comment files

Diff pairing and formatting

Train/val/test split

Tokenization, padding, batching

Batch-shape verification

Final training performed on 300k samples, not full dataset, to fit GPU memory.

âœ… Training Pipeline (GPU)

HuggingFace Transformers + PyTorch

Custom collate_fn

Label masking via -100

Gradient clipping

AMP disabled when debugging NaN loss

Model saved in .keras format (preferred)

ğŸ“ Project Structure

Below is the uploaded repo structure, with large dataset files removed, and no environment, vector DB, or database folders listed.

ai-code-reviewer/
â”‚
â”œâ”€â”€ 1.data Loading.ipynb
â”œâ”€â”€ 2.data wrangling.ipynb
â”œâ”€â”€ 3.formatting.ipynb
â”œâ”€â”€ 4.train_val_test_split.ipynb
â”œâ”€â”€ 5.tokenization_padding_batch_testing.ipynb
â”‚
â”œâ”€â”€ code-review-model-training (kaggle_trained).ipynb
â”œâ”€â”€ code-review-model-training(full_scale_local_run).ipynb
â”œâ”€â”€ local_model_testing.ipynb
â”‚
â”œâ”€â”€ app/                     # App folder (UI/API for inference)
â”‚
â”œâ”€â”€ model_download_v3/       # Saved model weights/checkpoints
â”‚
â”œâ”€â”€ venv/                    # Local virtual environment
â”‚
â”œâ”€â”€ README.md                # This file
â””â”€â”€ rev-rec-projects.pdf     # Research reference (kept small)


NOTE:
All huge .jsonl, .csv, .feather, and .zip dataset files were removed from this structure because they are too large for GitHub.

âš™ï¸ Technologies Used

Python

PyTorch

HuggingFace Transformers (FLAN-T5)

Jupyter Notebooks

Virtualenv (not Conda)

GPU training (local + Kaggle)

ğŸ§ª Model Output Format

The trained model generates:

1ï¸âƒ£ Suggested Review

A clearer version of the PR comment.

2ï¸âƒ£ Reasoning

Why the change is needed.

3ï¸âƒ£ Fix Patch

Minimal actionable diff:

Replace these lines:
<old>

With this:
<new>


Designed for easy integration with future GitHub automation.

ğŸ”® Future Enhancements

Add retrieval-augmented context (vector DB)

Larger model variants (base/large)

Integrate GitHub webhooks for real-time PR review

Web dashboard for analytics

ğŸ‘¤ Author

A developer building a real, production-grade ML portfolio with hands-on experimentation, GPU-based training, and structured dataset design.
