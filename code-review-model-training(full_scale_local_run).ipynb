{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:06:54.737263Z",
     "iopub.status.busy": "2025-11-22T09:06:54.737043Z",
     "iopub.status.idle": "2025-11-22T09:06:59.627065Z",
     "shell.execute_reply": "2025-11-22T09:06:59.625902Z",
     "shell.execute_reply.started": "2025-11-22T09:06:54.737225Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "!pip install protobuf==3.20.3\n",
    "# for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:06:59.629790Z",
     "iopub.status.busy": "2025-11-22T09:06:59.629491Z",
     "iopub.status.idle": "2025-11-22T09:07:02.789130Z",
     "shell.execute_reply": "2025-11-22T09:07:02.788584Z",
     "shell.execute_reply.started": "2025-11-22T09:06:59.629757Z"
    },
    "papermill": {
     "duration": 0.01316,
     "end_time": "2025-11-19T14:54:18.792965",
     "exception": false,
     "start_time": "2025-11-19T14:54:18.779805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "path = \"/kaggle/input/code-review-model-train-test-val-jsnol-files/val_data.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ex = json.loads(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:02.790260Z",
     "iopub.status.busy": "2025-11-22T09:07:02.789877Z",
     "iopub.status.idle": "2025-11-22T09:07:35.476985Z",
     "shell.execute_reply": "2025-11-22T09:07:35.476391Z",
     "shell.execute_reply.started": "2025-11-22T09:07:02.790218Z"
    },
    "papermill": {
     "duration": 13.709932,
     "end_time": "2025-11-19T14:54:32.505469",
     "exception": false,
     "start_time": "2025-11-19T14:54:18.795537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
    "model_name = 't5-small'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:35.478635Z",
     "iopub.status.busy": "2025-11-22T09:07:35.478060Z",
     "iopub.status.idle": "2025-11-22T09:07:35.482124Z",
     "shell.execute_reply": "2025-11-22T09:07:35.481406Z",
     "shell.execute_reply.started": "2025-11-22T09:07:35.478611Z"
    },
    "papermill": {
     "duration": 0.008183,
     "end_time": "2025-11-19T14:54:32.516917",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.508734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_input_tok = 256\n",
    "max_target_tok = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:35.483671Z",
     "iopub.status.busy": "2025-11-22T09:07:35.482858Z",
     "iopub.status.idle": "2025-11-22T09:07:35.533770Z",
     "shell.execute_reply": "2025-11-22T09:07:35.533221Z",
     "shell.execute_reply.started": "2025-11-22T09:07:35.483639Z"
    },
    "papermill": {
     "duration": 0.016069,
     "end_time": "2025-11-19T14:54:32.535872",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.519803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_inputs = tokenizer(ex['prompt'], truncation = True, max_length = max_input_tok)\n",
    "enc_target = tokenizer(ex['completion'], truncation = True, max_length = max_target_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:35.534677Z",
     "iopub.status.busy": "2025-11-22T09:07:35.534480Z",
     "iopub.status.idle": "2025-11-22T09:07:35.544447Z",
     "shell.execute_reply": "2025-11-22T09:07:35.543745Z",
     "shell.execute_reply.started": "2025-11-22T09:07:35.534661Z"
    },
    "papermill": {
     "duration": 0.009398,
     "end_time": "2025-11-19T14:54:32.548298",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.538900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(enc_inputs['input_ids'])\n",
    "attention_mask = torch.tensor(enc_inputs['attention_mask'])\n",
    "labels = torch.tensor(enc_target['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:35.546731Z",
     "iopub.status.busy": "2025-11-22T09:07:35.546540Z",
     "iopub.status.idle": "2025-11-22T09:07:35.555930Z",
     "shell.execute_reply": "2025-11-22T09:07:35.555405Z",
     "shell.execute_reply.started": "2025-11-22T09:07:35.546716Z"
    },
    "papermill": {
     "duration": 0.008541,
     "end_time": "2025-11-19T14:54:32.574367",
     "exception": false,
     "start_time": "2025-11-19T14:54:32.565826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"input_ids\" : input_ids.unsqueeze(0),\n",
    "    \"attention_mask\" : attention_mask.unsqueeze(0),\n",
    "    \"labels\" : labels.unsqueeze(0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:35.556841Z",
     "iopub.status.busy": "2025-11-22T09:07:35.556618Z",
     "iopub.status.idle": "2025-11-22T09:07:35.566480Z",
     "shell.execute_reply": "2025-11-22T09:07:35.565735Z",
     "shell.execute_reply.started": "2025-11-22T09:07:35.556817Z"
    },
    "papermill": {
     "duration": 0.011683,
     "end_time": "2025-11-19T14:56:25.425974",
     "exception": false,
     "start_time": "2025-11-19T14:56:25.414291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = [{\"input_ids\": b[\"input_ids\"], \"attention_mask\": b.get(\"attention_mask\", None)} for b in batch]\n",
    "    padded = tokenizer.pad(inputs, return_tensors=\"pt\")\n",
    "\n",
    "    labels = [b[\"labels\"] for b in batch]\n",
    "    padded_labels = tokenizer.pad({\"input_ids\": labels}, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    padded_labels[padded_labels == pad_id] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": padded[\"input_ids\"],\n",
    "        \"attention_mask\": padded[\"attention_mask\"],\n",
    "        \"labels\": padded_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:35.567472Z",
     "iopub.status.busy": "2025-11-22T09:07:35.567206Z",
     "iopub.status.idle": "2025-11-22T09:07:37.259093Z",
     "shell.execute_reply": "2025-11-22T09:07:37.258286Z",
     "shell.execute_reply.started": "2025-11-22T09:07:35.567456Z"
    },
    "papermill": {
     "duration": 43.287067,
     "end_time": "2025-11-19T14:57:08.716479",
     "exception": false,
     "start_time": "2025-11-19T14:56:25.429412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer,\n",
    "                 max_input_len=256, max_target_len=128):\n",
    "\n",
    "        self.path = path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "\n",
    "        self._offsets = []\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            offset = f.tell()\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                self._offsets.append(offset)\n",
    "                offset = f.tell()\n",
    "                line = f.readline()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._offsets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.seek(self._offsets[idx])\n",
    "            rec = json.loads(f.readline())\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            rec[\"prompt\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_input_len,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        tgt = self.tokenizer(\n",
    "            rec[\"completion\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_target_len\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"labels\": tgt[\"input_ids\"]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "path = \"/kaggle/input/code-review-model-train-test-val-jsnol-files/val_data.jsonl\"\n",
    "\n",
    "train_dataset = PRDataset(\n",
    "    path,\n",
    "    tokenizer,\n",
    "    max_input_len=256,\n",
    "    max_target_len=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:37.260295Z",
     "iopub.status.busy": "2025-11-22T09:07:37.259932Z",
     "iopub.status.idle": "2025-11-22T09:07:37.907638Z",
     "shell.execute_reply": "2025-11-22T09:07:37.907059Z",
     "shell.execute_reply.started": "2025-11-22T09:07:37.260266Z"
    },
    "papermill": {
     "duration": 2.857014,
     "end_time": "2025-11-19T14:57:11.577036",
     "exception": false,
     "start_time": "2025-11-19T14:57:08.720022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_dataset = PRDataset(\n",
    "    \"/kaggle/input/code-review-model-train-test-val-jsnol-files/val_data.jsonl\",\n",
    "    tokenizer,\n",
    "    max_input_len=256,\n",
    "    max_target_len=128\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:37.908497Z",
     "iopub.status.busy": "2025-11-22T09:07:37.908287Z",
     "iopub.status.idle": "2025-11-22T09:07:38.480658Z",
     "shell.execute_reply": "2025-11-22T09:07:38.479354Z",
     "shell.execute_reply.started": "2025-11-22T09:07:37.908481Z"
    },
    "papermill": {
     "duration": 0.145573,
     "end_time": "2025-11-19T14:57:11.726594",
     "exception": false,
     "start_time": "2025-11-19T14:57:11.581021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "assert batch['input_ids'].ndim == 2\n",
    "print(batch['input_ids'].shape, batch['attention_mask'].shape, batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T09:07:38.482686Z",
     "iopub.status.busy": "2025-11-22T09:07:38.482452Z",
     "iopub.status.idle": "2025-11-22T09:17:44.442861Z",
     "shell.execute_reply": "2025-11-22T09:17:44.442053Z",
     "shell.execute_reply.started": "2025-11-22T09:07:38.482653Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-11-19T14:57:11.730438",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils as nn_utils\n",
    "\n",
    "torch.backends.cudnn.benchmark = True \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.config.use_cache = False\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "ACCUM_STEPS = 8 \n",
    "scaler = GradScaler()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(1,6):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    step_count = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        # move tensors to device\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        labels = batch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "                use_cache=False\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss = loss / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            # clip grads (optional)\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn_utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * ACCUM_STEPS  # accumulate back to per-step loss\n",
    "        step_count += 1\n",
    "\n",
    "    avg_train_loss = total_loss / max(1, step_count)\n",
    "    print(f\"Epoch {epoch} train avg loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    with torch.no_grad():\n",
    "        for vbatch in val_loader:\n",
    "            v_input_ids = vbatch['input_ids'].to(device, non_blocking=True)\n",
    "            v_attention_mask = vbatch['attention_mask'].to(device, non_blocking=True)\n",
    "            v_labels = vbatch['labels'].to(device, non_blocking=True)\n",
    "            with autocast():\n",
    "                vout = model(\n",
    "                    input_ids=v_input_ids,\n",
    "                    attention_mask=v_attention_mask,\n",
    "                    labels=v_labels,\n",
    "                    use_cache=False\n",
    "                )\n",
    "            val_loss += vout.loss.item()\n",
    "            val_steps += 1\n",
    "    print(f\"Epoch {epoch} val avg loss: {val_loss / max(1, val_steps):.4f}\")\n",
    "    \n",
    "model.save_pretrained(\"/kaggle/working/\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working/\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8779781,
     "sourceId": 13791082,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-19T14:54:15.193838",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
